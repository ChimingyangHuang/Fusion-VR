{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation Part(Only need to run once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://urldefense.com/v3/__https://localhost:8080/__;!!Mih3wA!Eje2quypq1bAeOMOG3OnSP2svxHfzube5cergsflZZBbbXXWH87Q4OGbjy9vgwGZGQCT2s2pIsZdY1g6zw$ "
    },
    "collapsed": true,
    "id": "fB_1QBm_6zRh",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "9c9da560-4052-48eb-800b-6bca8f65b94a"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cd models/research\n",
    "# Compile protos.\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "# Install TensorFlow Object Detection API.\n",
    "cp object_detection/packages/tf1/setup.py .\n",
    "python3 -m pip install ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "jCZFtXd3EdYD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-08 17:23:30.100391: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n",
      "2023-09-08 17:23:30.100421: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2023-09-08 17:23:30.100436: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2023-09-08 17:23:30.100520: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-09-08 17:23:30.100563: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import io\n",
    "import xml.etree.ElementTree as ET\n",
    "import argparse\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from object_detection.utils import dataset_util, label_map_util, visualization_utils as viz_utils\n",
    "from collections import namedtuple\n",
    "import time\n",
    "import tensorflow\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "from collections import deque\n",
    "from moviepy.editor import VideoFileClip,AudioFileClip,concatenate_videoclips\n",
    "# setting min confidence threshold\n",
    "MIN_CONF_THRESH=.25\n",
    "\n",
    "PATH_TO_SAVED_MODEL_ALL=r'./source/saved_model'\n",
    "\n",
    "detect_fn = tensorflow.saved_model.load(PATH_TO_SAVED_MODEL_ALL)\n",
    "\n",
    "\n",
    "PATH_TO_LABELS_ALL=r'./source/annotations/label_map.pbtxt'\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS_ALL,use_display_name=True)\n",
    "\n",
    "red_model=tensorflow.keras.models.load_model(r'./source/model/arrow_red_model.h5')\n",
    "left_model=tensorflow.keras.models.load_model(r'./source/model/arrow_left_model.h5')\n",
    "avatar_is_blue_model=tensorflow.keras.models.load_model(r'./source/model/avatar_is_blue_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zcxInQ7SxbjV"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "    Puts image into numpy array of shape (height, width, channels), where channels=3 for RGB to feed into tensorflow graph.\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB))\n",
    "\n",
    "def deduplicate(detections,conf_thresh):\n",
    "  \"\"\"\n",
    "    deduplicate each class in detection, only keep the one with highest confidence score\n",
    "\n",
    "    Parameters:\n",
    "    detection: detection generated by detect_fn.\n",
    "\n",
    "    Returns:\n",
    "    detection that has only each class with highest confidence score\n",
    "  \"\"\"\n",
    "\n",
    "  appearedClassNum = []\n",
    "  appearedIndex=[]\n",
    "  for i in range(detections['detection_boxes'].shape[0]):\n",
    "    class_num = int(detections['detection_classes'][i])\n",
    "    if class_num not in appearedClassNum and detections['detection_scores'][i]>conf_thresh:\n",
    "      appearedClassNum.append(class_num)\n",
    "      appearedIndex.append(i)\n",
    "    if len(appearedClassNum) == 3:\n",
    "      break\n",
    "  appearedClassNum = sorted(appearedClassNum)\n",
    "  detections['detection_boxes'] = np.array([detections['detection_boxes'][i] for i in appearedIndex]).reshape((len(appearedClassNum), 4))\n",
    "  detections['detection_classes'] =  np.array([detections['detection_classes'][i] for i in appearedIndex]).reshape((len(appearedClassNum),))\n",
    "  detections['detection_scores'] =  np.array([detections['detection_scores'][i] for i in appearedIndex]).reshape((len(appearedClassNum),))\n",
    "  detections['num_detections']=len(appearedClassNum)\n",
    "  return detections\n",
    "\n",
    "def crop_arrow_image(image, detections):\n",
    "    \"\"\"\n",
    "    Crop an image with a given bounding box.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): The input image to crop.\n",
    "    bbox (tuple): A tuple of four integers (xmin, ymin, xmax, ymax) that specify the bounding box coordinates.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The cropped image.\n",
    "    \"\"\"\n",
    "\n",
    "    HEIGHT=1080\n",
    "    LENGTH=1920\n",
    "    for i in range(detections['detection_boxes'].shape[0]):\n",
    "      if detections['detection_classes'][i]==2 and detections['detection_scores'][i]>=0.25: #label of arrow\n",
    "        yminr, xminr, ymaxr, xmaxr = detections['detection_boxes'][i]\n",
    "        ymin = int(yminr * HEIGHT)\n",
    "        xmin = int(xminr * LENGTH)\n",
    "        ymax = int(ymaxr * HEIGHT)\n",
    "        xmax = int(xmaxr * LENGTH)\n",
    "\n",
    "        cropped_image = image[ymin:ymax, xmin:xmax]\n",
    "        return cropped_image\n",
    "    return None\n",
    "\n",
    "def preprocess_image(im, desired_size=224, resample=Image.BOX):\n",
    "    \"\"\"\n",
    "    preprocess the arrow image resolution to 224x224 to feed in neural network\n",
    "\n",
    "    Parameters:\n",
    "    im: PIL image class\n",
    "\n",
    "    Returns:\n",
    "    im: Image after resample to 224x224\n",
    "    \"\"\"\n",
    "\n",
    "    im = im.resize((desired_size, )*2, resample=resample)\n",
    "    return im\n",
    "\n",
    "def predict_red(img_array,model):\n",
    "  \"\"\"\n",
    "  predict if img_array is a red arrow or a white arrow\n",
    "\n",
    "  Parameters:\n",
    "  img_array: numpyndarray [0..1], shape=[224,224,3] representing the arrow image\n",
    "  model: model for predicting red arrow.\n",
    "\n",
    "  Returns:\n",
    "  boolean: True if arrow red, False if arrow white\n",
    "  \"\"\"\n",
    "\n",
    "  img_array=np.expand_dims(img_array, axis=0)\n",
    "  prediction = model.predict(img_array,verbose=0)\n",
    "  binary_prediction = int(prediction[0][0] > 0.5)\n",
    "  if binary_prediction == 1:\n",
    "      return True\n",
    "  else:\n",
    "      return False\n",
    "\n",
    "def predict_left(img_array,model):\n",
    "  \"\"\"\n",
    "  predict if img_array is a left arrow or a right arrow\n",
    "\n",
    "  Parameters:\n",
    "  img_array: numpyndarray [0..1], shape=[224,224,3] representing the arrow image\n",
    "  model: model for predicting direction of the arrow./~bseward/103a_fall22/\n",
    "\n",
    "  Returns:\n",
    "  boolean: True if arrow is left, False if arrow is right\n",
    "  \"\"\"\n",
    "  img_array=np.expand_dims(img_array, axis=0)\n",
    "  prediction = model.predict(img_array,verbose=0)\n",
    "  binary_prediction = int(prediction[0][0] > 0.5)\n",
    "  if binary_prediction == 1:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def impose_left_text(img_array, isLeft=False):\n",
    "  \"\"\"\n",
    "    write arrow direction result in prediction video\n",
    "\n",
    "    Parameters:\n",
    "    img_array: numpyndarray [0...255], shape=[1080,1920,3] representing the whole image\n",
    "    isLeft: supposed arrow presents, if the arrow is left in this image\n",
    "\n",
    "    Returns:\n",
    "    imposed_array: the whole image imposed with direction of arrow\n",
    "  \"\"\"\n",
    "\n",
    "  img = Image.fromarray(np.uint8(img_array))\n",
    "  draw = ImageDraw.Draw(img)\n",
    "  if isLeft==True:\n",
    "    text_to_impose='left arrow'\n",
    "  else:\n",
    "    text_to_impose='right arrow'\n",
    "  font = ImageFont.truetype(r'arial.ttf', 90)\n",
    "  draw.text((10, 10), text_to_impose,font=font, fill=(52, 235, 70))\n",
    "  # Convert the PIL Image back to a NumPy array\n",
    "  imposed_array = np.array(img)\n",
    "  return imposed_array\n",
    "\n",
    "def impose_red_text(img_array, isRed=False):\n",
    "  \"\"\"\n",
    "    write arrow color result in prediction video\n",
    "\n",
    "    Parameters:\n",
    "    img_array: numpyndarray [0...255], shape=[1080,1920,3] representing the whole image\n",
    "    isRed: supposed arrow presents, if the arrow is red or white in this image\n",
    "\n",
    "    Returns:\n",
    "    imposed_array: the whole image imposed with color of arrow\n",
    "  \"\"\"\n",
    "\n",
    "  img = Image.fromarray(np.uint8(img_array))\n",
    "  draw = ImageDraw.Draw(img)\n",
    "  font = ImageFont.truetype(r'arial.ttf', 100)\n",
    "  if isRed==True:\n",
    "    text_to_impose='red arrow'\n",
    "    draw.text((10, 110), text_to_impose ,font=font, fill=(255, 0, 0))\n",
    "  else:\n",
    "    text_to_impose='white arrow'\n",
    "    draw.text((10, 110), text_to_impose,font=font, fill=(180, 180, 200))\n",
    "  # Convert the PIL Image back to a NumPy array\n",
    "  imposed_array = np.array(img)\n",
    "  return imposed_array\n",
    "\n",
    "def impose_avatar_text(img_array, isBlue):\n",
    "  img = Image.fromarray(np.uint8(img_array))\n",
    "  draw = ImageDraw.Draw(img)\n",
    "  font = ImageFont.truetype(r'arial.ttf', 100)\n",
    "  if isBlue==True:\n",
    "    text_to_impose='blue avatar'\n",
    "    draw.text((10, 770), text_to_impose ,font=font, fill=(150, 150, 150))\n",
    "  else:\n",
    "    text_to_impose='green avatar'\n",
    "    draw.text((10, 770), text_to_impose,font=font, fill=(150, 150, 150))\n",
    "  # Convert the PIL Image back to a NumPy array\n",
    "  imposed_array = np.array(img)\n",
    "  return imposed_array\n",
    "\n",
    "def impose_frame_count(img_array, frame_count):\n",
    "  img = Image.fromarray(np.uint8(img_array))\n",
    "  draw = ImageDraw.Draw(img)\n",
    "  font = ImageFont.truetype(r'arial.ttf', 100)\n",
    "  text_to_impose='frame_count: '+str(frame_count)\n",
    "  draw.text((10, 870), text_to_impose ,font=font, fill=(108,108,108))\n",
    "  # Convert the PIL Image back to a NumPy array\n",
    "  imposed_array = np.array(img)\n",
    "  return imposed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "o_5OsgO_9FeH"
   },
   "outputs": [],
   "source": [
    "def get_detections(image_np, detect_fn):\n",
    "  input_tensor = tensorflow.convert_to_tensor(image_np)\n",
    "  input_tensor = input_tensor[tensorflow.newaxis, ...]\n",
    "  detections = detect_fn(input_tensor)\n",
    "  num_detections = int(detections.pop('num_detections'))\n",
    "  detections = {key: value[0, :num_detections].numpy()\n",
    "                for key, value in detections.items()}\n",
    "  detections['num_detections'] = num_detections\n",
    "  detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "  return detections\n",
    "\n",
    "def grayscale_yellow(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    yellow_hue_lower = np.array([20, 50, 100])  # Lower yellow hue range for light yellow\n",
    "    yellow_hue_upper = np.array([40, 255, 255])  # Upper yellow hue range\n",
    "    yellow_mask = cv2.inRange(hsv, yellow_hue_lower, yellow_hue_upper)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    gray_yellow = cv2.bitwise_and(gray, gray, mask=yellow_mask)\n",
    "    return gray_yellow\n",
    "\n",
    "def get_gaze(image_np):\n",
    "    blurred = cv2.GaussianBlur(image_np, (21, 21), 0)\n",
    "    gray = grayscale_yellow(blurred)\n",
    "    # Threshold the grayscale image to create a binary image\n",
    "    _, binary = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Find contours in the binary image\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for contour in contours:\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        area = cv2.contourArea(contour)\n",
    "\n",
    "        # Check if the perimeter is non-zero before calculating circularity\n",
    "        if perimeter > 0:\n",
    "            circularity = 4 * np.pi * (area / (perimeter * perimeter))\n",
    "            (x, y), radius = cv2.minEnclosingCircle(contour)\n",
    "            if circularity > 0.5 and radius>20:\n",
    "                ymin=int(y-radius)\n",
    "                xmin=int(x-radius)\n",
    "                ymax=int(y+radius)\n",
    "                xmax=int(x+radius)\n",
    "                ymin=max(ymin,0)\n",
    "                xmin=max(xmin,0)\n",
    "                ymax=min(ymax,1080)\n",
    "                xmax=min(xmax,1920)\n",
    "\n",
    "                return True, (ymin, xmin, ymax, xmax)\n",
    "    return False, None\n",
    "\n",
    "\n",
    "def impose_gaze_sqaure(img_array, isGaze,gaze_bbox):\n",
    "  \"\"\"\n",
    "    draw a rectangle around the gaze in prediction video\n",
    "\n",
    "    Parameters:\n",
    "    img_array: numpyndarray [0...255], shape=[1080,1920,3] representing the whole image\n",
    "    isGaze: if gaze exists or not\n",
    "\n",
    "    Returns:\n",
    "    imposed_array: the whole image imposed with a rectangular around circle\n",
    "  \"\"\"\n",
    "\n",
    "  img = Image.fromarray(np.uint8(img_array))\n",
    "  draw = ImageDraw.Draw(img)\n",
    "  font = ImageFont.truetype(r'arial.ttf', 90)\n",
    "  if isGaze==True:\n",
    "    text_to_impose=\"Gaze\"\n",
    "    draw.text((10, 210), text_to_impose ,font=font, fill=(255, 255, 0))\n",
    "    xmin=gaze_bbox[1]\n",
    "    ymin=gaze_bbox[0]\n",
    "    xmax=gaze_bbox[3]\n",
    "    ymax=gaze_bbox[2]\n",
    "    draw.rectangle([(xmin,ymin), (xmax, ymax)], outline=(0, 128, 255), width=5)\n",
    "  imposed_array = np.array(img)\n",
    "  return imposed_array\n",
    "\n",
    "def get_object_and_bbox(detections):\n",
    "  '''\n",
    "  use after deduplication, bbox format:(ymin,xmin,ymax,xmax)\n",
    "  '''\n",
    "  avatar,avatar_bbox, arrow, arrow_bbox, sphere,sphere_bbox=[None for i in range(6)]\n",
    "  avatar=False\n",
    "  arrow=False\n",
    "  sphere=False\n",
    "\n",
    "  HEIGHT=1080\n",
    "  LENGTH=1920\n",
    "  for i in range(detections['detection_boxes'].shape[0]):\n",
    "    if detections['detection_classes'][i]==2: #label of arrow\n",
    "      yminr, xminr, ymaxr, xmaxr = detections['detection_boxes'][i]\n",
    "      ymin = int(yminr * HEIGHT)\n",
    "      xmin = int(xminr * LENGTH)\n",
    "      ymax = int(ymaxr * HEIGHT)\n",
    "      xmax = int(xmaxr * LENGTH)\n",
    "      arrow=True\n",
    "      arrow_bbox=(ymin, xmin, ymax, xmax)\n",
    "    elif detections['detection_classes'][i]==1:\n",
    "      yminr, xminr, ymaxr, xmaxr = detections['detection_boxes'][i]\n",
    "      ymin = int(yminr * HEIGHT)\n",
    "      xmin = int(xminr * LENGTH)\n",
    "      ymax = int(ymaxr * HEIGHT)\n",
    "      xmax = int(xmaxr * LENGTH)\n",
    "      sphere=True\n",
    "      sphere_bbox=(ymin, xmin, ymax, xmax)\n",
    "    elif detections['detection_classes'][i]==3:\n",
    "      yminr, xminr, ymaxr, xmaxr = detections['detection_boxes'][i]\n",
    "      ymin = int(yminr * HEIGHT)\n",
    "      xmin = int(xminr * LENGTH)\n",
    "      ymax = int(ymaxr * HEIGHT)\n",
    "      xmax = int(xmaxr * LENGTH)\n",
    "      avatar=True\n",
    "      avatar_bbox=(ymin, xmin, ymax, xmax)\n",
    "\n",
    "  return avatar,avatar_bbox, arrow, arrow_bbox, sphere,sphere_bbox\n",
    "\n",
    "def gaze_at_arrow(gaze,gaze_box,arrow, arrow_bbox):\n",
    "  return False\n",
    "\n",
    "def gaze_at_avatar(gaze,gaze_box, avatar, avatar_bbox):\n",
    "  return False\n",
    "\n",
    "def sphere_at_avatar(sphere,sphere_box,avatar, avatar_bbox):\n",
    "  return False\n",
    "\n",
    "def arrow_is_left_white(image,detections,left_model,red_model):\n",
    "  arrow=crop_arrow_image(image,detections)\n",
    "  if type(arrow)!=type(None):\n",
    "    arrow=preprocess_image(Image.fromarray(arrow))\n",
    "    arrow= np.array(arrow)\n",
    "    arrow_float=arrow.astype(float)\n",
    "    arrow_float=arrow_float*1./255\n",
    "    isRed=predict_red(arrow_float,red_model)\n",
    "    isLeft=predict_left(arrow_float,left_model)\n",
    "    return isLeft,not isRed\n",
    "  else:\n",
    "    return False,False\n",
    "def crop_avatar_image(image, detections):\n",
    "    \"\"\"\n",
    "    Crop an image with a given bounding box.\n",
    "\n",
    "    Parameters:\n",
    "    image (numpy.ndarray): The input image to crop.\n",
    "    bbox (tuple): A tuple of four integers (xmin, ymin, xmax, ymax) that specify the bounding box coordinates.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: The cropped image.\n",
    "    \"\"\"\n",
    "\n",
    "    HEIGHT=1080\n",
    "    LENGTH=1920\n",
    "    for i in range(detections['detection_boxes'].shape[0]):\n",
    "      if detections['detection_classes'][i]==3 and detections['detection_scores'][i]>=0.25: #label of arrow\n",
    "        yminr, xminr, ymaxr, xmaxr = detections['detection_boxes'][i]\n",
    "        ymin = int(yminr * HEIGHT)\n",
    "        xmin = int(xminr * LENGTH)\n",
    "        ymax = int(ymaxr * HEIGHT)\n",
    "        xmax = int(xmaxr * LENGTH)\n",
    "        cropped_image = image[ymin:ymax, xmin:xmax]\n",
    "        # if ss==True:\n",
    "        #   save_dir=r'/content/drive/MyDrive/avatar/'\n",
    "        #   image_pil = Image.fromarray(cropped_image.astype(np.uint8))\n",
    "        #   file_name = os.path.join(save_dir, str(fc)+\".jpg\")\n",
    "        #   image_pil.save(file_name)\n",
    "        return cropped_image\n",
    "    return None\n",
    "\n",
    "def get_avatar_is_blue(image, detections,avatar_is_blue_model):\n",
    "  avatar=crop_avatar_image(image,detections)\n",
    "  if type(avatar)!=type(None):\n",
    "    avatar=preprocess_image(Image.fromarray(avatar))\n",
    "    avatar= np.array(avatar)\n",
    "    avatar_float=avatar.astype(float)\n",
    "    avatar_float=avatar_float*1./255\n",
    "    isBlue=predict_red(avatar_float,avatar_is_blue_model)\n",
    "    ret=-1 if isBlue==True else 1\n",
    "    return ret\n",
    "  else:\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jBOR-Q-XiF2f"
   },
   "outputs": [],
   "source": [
    "def check_bbox_overlap(bbox_1,bbox_2,tolerance=0):\n",
    "    ymin_1, xmin_1, ymax_1, xmax_1 = bbox_1\n",
    "    ymin_2, xmin_2, ymax_2, xmax_2 = bbox_2\n",
    "\n",
    "    # Calculate the intersection coordinates\n",
    "    xmin_intersection = max(xmin_1, xmin_2)\n",
    "    ymin_intersection = max(ymin_1, ymin_2)\n",
    "    xmax_intersection = min(xmax_1, xmax_2)\n",
    "    ymax_intersection = min(ymax_1, ymax_2)\n",
    "\n",
    "    # Check if there is an intersection\n",
    "    if xmin_intersection < xmax_intersection and ymin_intersection < ymax_intersection:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "def get_gaze_at_arrow(gaze, gaze_bbox,arrow,arrow_bbox,tolerance=0):\n",
    "  if gaze==True and arrow==True:\n",
    "    return check_bbox_overlap(gaze_bbox,arrow_bbox,tolerance)\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def get_gaze_at_avatar(gaze, gaze_bbox,avatar,avatar_bbox,tolerance=0):\n",
    "  if gaze==True and avatar==True:\n",
    "    return check_bbox_overlap(gaze_bbox,avatar_bbox,tolerance)\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def get_sphere_at_avatar(sphere, sphere_bbox,avatar,avatar_bbox,tolerance=0):\n",
    "  if sphere==True and avatar==True:\n",
    "    return check_bbox_overlap(sphere_bbox,avatar_bbox,tolerance)\n",
    "  else:\n",
    "    return False\n",
    "def impose_inference_text(image_np,gaze_at_arrow,gaze_at_avatar,sphere_at_avatar):\n",
    "\n",
    "  '''\n",
    "  impose the text of gaze_at_arrow, gaze_at_avatar and sphere_at_avatar on image\n",
    "  image: image np_array\n",
    "  text: text to impose\n",
    "  '''\n",
    "  img = Image.fromarray(np.uint8(image_np))\n",
    "  draw = ImageDraw.Draw(img)\n",
    "  font = ImageFont.truetype(r'arial.ttf', 90)\n",
    "  if gaze_at_arrow==True:\n",
    "    text_to_impose=\"gaze_at_arrow\"\n",
    "    draw.text((10, 310), text_to_impose ,font=font, fill=(245, 11, 220))\n",
    "  if gaze_at_avatar==True:\n",
    "    text_to_impose=\"gaze_at_avatar\"\n",
    "    draw.text((10, 410), text_to_impose ,font=font, fill=(11, 226, 245))\n",
    "  if sphere_at_avatar==True:\n",
    "    text_to_impose=\"sphere_at_avatar\"\n",
    "    draw.text((10, 510), text_to_impose ,font=font, fill=(104, 67, 222))\n",
    "  imposed_array = np.array(img)\n",
    "  return imposed_array\n",
    "\n",
    "def impose_shot_detected_text(image_np,shot_detected):\n",
    "  img = Image.fromarray(np.uint8(image_np))\n",
    "  draw = ImageDraw.Draw(img)\n",
    "  font = ImageFont.truetype(r'arial.ttf', 90)\n",
    "  if shot_detected==True:\n",
    "    text_to_impose=\"shot detected\"\n",
    "    draw.text((10, 610), text_to_impose ,font=font, fill=(126, 231, 188))\n",
    "  imposed_array = np.array(img)\n",
    "  return imposed_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "KzaDm3D2GQMr"
   },
   "outputs": [],
   "source": [
    "def get_max_values(arr):\n",
    "    arr = arr[::-1]\n",
    "    result = []\n",
    "    window = deque()\n",
    "    max_value = float('-inf')\n",
    "\n",
    "    for num in arr:\n",
    "        window.append(num)\n",
    "\n",
    "        if num >= max_value:\n",
    "            max_value = num\n",
    "\n",
    "        if len(window) > 44100*0.04:\n",
    "            if window[0] == max_value:\n",
    "                window.popleft()\n",
    "                max_value = max(window)\n",
    "            else:\n",
    "                window.popleft()\n",
    "\n",
    "        result.append(max_value)\n",
    "\n",
    "    return result[::-1]\n",
    "\n",
    "def create_shot(PATH,amplitude_threshold=0.30):\n",
    "  #audio_data=AudioFileClip(PATH).to_soundarray() #audio.to_soundarray normalize the amplitude\n",
    "  #audio_data=audio_data[:,0]\n",
    "    \n",
    "    \n",
    "    \n",
    "  audio_data=np.stack(AudioFileClip(PATH).iter_frames())[:,0]\n",
    "\n",
    "  shot=get_max_values(audio_data)\n",
    "  shot=np.array(shot)\n",
    "  shot=(shot>=amplitude_threshold)\n",
    "\n",
    "  time = np.linspace(0, audio_data.shape[0] / 44100, len(audio_data))\n",
    "  abnormal_segment = shot[int(44100*6):int(44100*6.001)+1]\n",
    "  time_segment = time[int(44100*6):int(44100*6.001)+1]\n",
    "\n",
    "  return shot\n",
    "\n",
    "from moviepy.editor import VideoFileClip, AudioClip\n",
    "\n",
    "def add_audio_to_video(audio_source_video_path, output_raw_path, output_path):\n",
    "    video = VideoFileClip(output_raw_path)\n",
    "    audio=VideoFileClip(audio_source_video_path).audio\n",
    "    print(audio)\n",
    "    video = video.set_audio(audio)\n",
    "    video.write_videofile(output_path, codec=\"rawvideo\",logger=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wI9_kKvvFh_i"
   },
   "outputs": [],
   "source": [
    "def post_processing_csv(CSV_PATH):\n",
    "  df = pd.read_csv(CSV_PATH)\n",
    "  #get coordinates of estimated sphere\n",
    "  indices = df[df['sphere_is_estimated'] == True].index\n",
    "  length=len(df)\n",
    "  for i in indices:\n",
    "    estimate_index=None\n",
    "    offset=1\n",
    "    while(True):\n",
    "      j=i-offset\n",
    "      if j>=0 and df.iloc[j]['sphere']==True:\n",
    "        estimate_index=j\n",
    "        break\n",
    "      j=i+offset\n",
    "      if j<length and df.iloc[j]['sphere']==True:\n",
    "        estimate_index=j\n",
    "        break\n",
    "      offset+=1\n",
    "    df.at[i, 'sphere'] = True\n",
    "    df.at[i, 'sphere_bbox'] = df.at[estimate_index, 'sphere_bbox']\n",
    "    df.at[i, 'sphere_ymin'] = df.at[estimate_index, 'sphere_ymin']\n",
    "    df.at[i, 'sphere_xmin'] = df.at[estimate_index, 'sphere_xmin']\n",
    "    df.at[i, 'sphere_ymax'] = df.at[estimate_index, 'sphere_ymax']\n",
    "    df.at[i, 'sphere_xmax'] = df.at[estimate_index, 'sphere_xmax']\n",
    "\n",
    "  #update count_arrow and count_avatar columns\n",
    "  arrow_count=0\n",
    "  avatar_count=0\n",
    "  #62 frames is 2500 ms, the interval we want\n",
    "  arrow_interval=62\n",
    "  avatar_interval=62\n",
    "  threshold=62\n",
    "  last_arrow=-62\n",
    "  last_avatar=-62\n",
    "  for index in range(len(df)):\n",
    "    is_arrow_in_5_frame=True\n",
    "    is_avatar_in_5_frame=True\n",
    "\n",
    "    if index-last_arrow>=threshold:\n",
    "      for j in range(5):\n",
    "        if index+j<len(df) and df.iloc[index+j]['arrow']!=True:\n",
    "          is_arrow_in_5_frame=False\n",
    "          break\n",
    "\n",
    "    if index-last_avatar>=threshold:\n",
    "      for j in range(5):\n",
    "        if index+j<len(df) and df.iloc[index+j]['avatar']!=True:\n",
    "          is_avatar_in_5_frame=False\n",
    "          break\n",
    "    if is_arrow_in_5_frame==True and index-last_arrow>=threshold:\n",
    "      arrow_count=arrow_count+1\n",
    "      df.at[index,'arrow_count']=arrow_count\n",
    "      last_arrow=index\n",
    "    if is_avatar_in_5_frame==True and index-last_avatar>=threshold:\n",
    "      avatar_count=avatar_count+1\n",
    "      df.at[index,'avatar_count']=avatar_count\n",
    "      last_avatar=index\n",
    "\n",
    "  #get first_frame_of_gaze_at_avatar\n",
    "  last_avatar_count=0\n",
    "  current_avatar_count=0\n",
    "  for index in range(len(df)):\n",
    "    if not pd.isnull(df.at[index,'avatar_count']):\n",
    "      current_avatar_count=df.at[index,'avatar_count']\n",
    "    if df.at[index,'gaze_at_avatar']==True and current_avatar_count!=last_avatar_count:\n",
    "      first_frame_of_gaze_at_avatar=True\n",
    "      last_avatar_count=current_avatar_count\n",
    "    else:\n",
    "      first_frame_of_gaze_at_avatar=False\n",
    "    df.at[index,'first_frame_of_gaze_at_avatar']=first_frame_of_gaze_at_avatar\n",
    "\n",
    "  #add arrow_is_5_to_8_frames_before_avatar, avatar_is_5_to_8_frames_after_arrow\n",
    "  for index in range(len(df)):\n",
    "    if not pd.isnull(df['arrow_count'][index]):\n",
    "      for i in range(5,9):\n",
    "        if (index+i)<len(df) and not pd.isnull(df.at[index+i,'avatar_count']):\n",
    "          df.at[index,'arrow_is_5_to_8_frames_before_avatar']=True\n",
    "          break\n",
    "      else:\n",
    "        df.at[index,'arrow_is_5_to_8_frames_before_avatar']=False\n",
    "    else:\n",
    "      df.at[index,'arrow_is_5_to_8_frames_before_avatar']=None\n",
    "  for index in range(len(df)):\n",
    "    if not pd.isnull(df['avatar_count'][index]):\n",
    "      for i in range(5,9):\n",
    "        if (index-i)>=0 and not pd.isnull(df.at[index-i,'arrow_count']):\n",
    "          df.at[index,'avatar_is_5_to_8_frames_after_arrow']=True\n",
    "          break\n",
    "      else:\n",
    "        df.at[index,'avatar_is_5_to_8_frames_after_arrow']=False\n",
    "    else:\n",
    "      df.at[index,'avatar_is_5_to_8_frames_after_arrow']=None\n",
    "\n",
    "  #add arrow_remains_longtime and avatar_remains_longtime\n",
    "  if 'BEAM' in CSV_PATH:\n",
    "    avatar_interval=60\n",
    "    arrow_interval=65\n",
    "  else:\n",
    "    avatar_interval=45\n",
    "    arrow_interval=50\n",
    "  for index in range(len(df)-66):\n",
    "    if not pd.isnull(df['arrow_count'][index]):\n",
    "      if df['arrow'][index+arrow_interval-1]==True and df['arrow'][index+arrow_interval]==True and df['arrow'][index+arrow_interval+1]==True:\n",
    "        df.at[index,'arrow_remains_longtime']=True\n",
    "      else:\n",
    "        df.at[index,'arrow_remains_longtime']=False\n",
    "\n",
    "    if not pd.isnull(df['avatar_count'][index]):\n",
    "      if df['avatar'][index+avatar_interval-1]==True and df['avatar'][index+avatar_interval]==True and df['avatar'][index+avatar_interval+1]==True:\n",
    "        df.at[index,'avatar_remains_longtime']=True\n",
    "      else:\n",
    "        df.at[index,'avatar_remains_longtime']=False\n",
    "  df = df.replace({True: 1, False: 0})\n",
    "\n",
    "  #add trial count\n",
    "  # for index in range(1,len(df)):\n",
    "  #   if not pd.isnull(df['arrow_count'][index]):\n",
    "  #     df.at[index,'trial_count']=df['trial_count'][index-1]+1;\n",
    "  #   else:\n",
    "  #     df.at[index,'trial_count']=df['trial_count'][index-1]\n",
    "  # for index in range(len(df)):\n",
    "  #   if df['arrow_is_5_to_8_frames_before_avatar'][index]==1 and df['gaze_at_arrow'][index]==1:\n",
    "  #     df.at[index,'trial_start_time']=df['timee'][index]\n",
    "  #   if df['first_frame_of_gaze_at_avatar'][index]==1:\n",
    "  #     df.at[index,'saccade_rt']=df['timee'][index]\n",
    "  #   if df['first_frame_of_shot'][index]==1:\n",
    "  #     df.at[index,'manual_rt']=df['timee'][index]\n",
    "\n",
    "  #formulate version:\n",
    "  for index in range(3,len(df)):\n",
    "    df.at[index,'trial_count']='=IF(ISNUMBER(M{ind1}),C{ind}+1,C{ind})'.format(ind1=index+2,ind=index+1)\n",
    "  for index in range(2,len(df)):\n",
    "    df.at[index,'trial_start_time']='=IF(N{ind}=1,A{ind},\"\")'.format(ind=index+2)\n",
    "    df.at[index,'saccade_rt']='=IF(S{ind}=1,A{ind},\"\")'.format(ind=index+2)\n",
    "    df.at[index,'manual_rt']='=IF(U{ind}=1,A{ind},\"\")'.format(ind=index+2)\n",
    "\n",
    "\n",
    "\n",
    "  #avatar_direction\n",
    "  for index in range(9,len(df)-1):\n",
    "    if df['avatar'][index]==1 and df['arrow'][index]==1:\n",
    "      count=0\n",
    "      sum=0\n",
    "      for i in range(index-9,index+1):\n",
    "        if not pd.isnull(df['avatar_LR'][i]):\n",
    "          count=count+1\n",
    "          sum=sum+df['avatar_LR'][i]\n",
    "      if count>=5:\n",
    "        df.at[index,'avatar_direction']=sum/count\n",
    "\n",
    "  #avatar_color\n",
    "  for index in range(9,len(df)-1):\n",
    "    if df['avatar'][index]==1:\n",
    "      count=0\n",
    "      sum=0\n",
    "      for i in range(index-9,index+1):\n",
    "        if not pd.isnull(df['avatar_is_blue'][i]):\n",
    "          count=count+1\n",
    "          sum=sum+df['avatar_is_blue'][i]\n",
    "      if count>=5:\n",
    "        df.at[index,'avatar_color']=sum/count\n",
    "\n",
    "  df.to_excel(CSV_PATH.split('.')[0]+'.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cNa2NIDfVRbE"
   },
   "outputs": [],
   "source": [
    "def process(VIDEO_PATH,OUTPUT_PATH,CSV_PATH,draw,beam):\n",
    "  data = []\n",
    "  arrow_is_5_to_8_frames_before_avatar,avatar_is_5_to_8_frames_after_arrow,timee,avatar,avatar_bbox,arrow,arrow_bbox,sphere,sphere_is_estimated,sphere_bbox,gaze,gaze_bbox, gaze_at_arrow,gaze_at_avatar,sphere_at_avatar,shot_detected,first_frame_of_shot,arrow_is_left,arrow_is_white,avatar_is_blue,first_frame_of_gaze_at_avatar,avatar_remains_longtime,arrow_remains_longtime=[None for i in range(23)]\n",
    "  arrow_count=None\n",
    "  avatar_count=None\n",
    "  avatar_LR=None\n",
    "\n",
    "  trial_count=0\n",
    "  trial_start_time=None\n",
    "  saccade_rt=None\n",
    "  manual_rt=None\n",
    "  avatar_direction=None\n",
    "  avatar_color=None\n",
    "\n",
    "  cap = cv2.VideoCapture(VIDEO_PATH)\n",
    "  frame_width = int(cap.get(3))\n",
    "  frame_height = int(cap.get(4))\n",
    "  frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "  num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "  print(\"Video resolution: {}x{}\".format(frame_width, frame_height))\n",
    "  print(\"Video fps: {}\".format(frame_rate))\n",
    "  print(\"Total number of frames: {}\".format(num_frames))\n",
    "  print(\"processing now\")\n",
    "  prev_frame_shot=False\n",
    "  if draw:\n",
    "    out = cv2.VideoWriter(OUTPUT_PATH,cv2.VideoWriter_fourcc(*'MJPG'), frame_rate, (frame_width,frame_height),True)\n",
    "    \n",
    "  frame_count = 0\n",
    "  start_time = time.time()\n",
    "  shot_raw=create_shot(VIDEO_PATH)\n",
    "  while(frame_count<num_frames): #csv: frame_count\n",
    "    # Capture frame-by-frame\n",
    "      if (beam==False and frame_count==num_frames//2):\n",
    "        out.release()\n",
    "        OUTPUT_PATH=OUTPUT_PATH.split(\".\")[0]+\" part2.\"+OUTPUT_PATH.split(\".\")[1]\n",
    "        out = cv2.VideoWriter(OUTPUT_PATH,cv2.VideoWriter_fourcc(*'MJPG'), frame_rate, (frame_width,frame_height),True)\n",
    "      if (beam==True and frame_count==num_frames//3):\n",
    "        out.release()\n",
    "        OUTPUT_PATH=OUTPUT_PATH.split(\".\")[0]+\" part2.\"+OUTPUT_PATH.split(\".\")[1]\n",
    "        out = cv2.VideoWriter(OUTPUT_PATH,cv2.VideoWriter_fourcc(*'MJPG'), frame_rate, (frame_width,frame_height),True)\n",
    "      elif(beam==True and frame_count==2*(num_frames//3)):\n",
    "        out.release()\n",
    "        OUTPUT_PATH=OUTPUT_PATH.split(\".\")[0]+\" part3.\"+OUTPUT_PATH.split(\".\")[1]\n",
    "        out = cv2.VideoWriter(OUTPUT_PATH,cv2.VideoWriter_fourcc(*'MJPG'), frame_rate, (frame_width,frame_height),True)\n",
    "\n",
    "      timee=frame_count/25\n",
    "      if frame_count%200==0:\n",
    "          print(frame_count)\n",
    "      ret, frame = cap.read()\n",
    "      if ret != True:\n",
    "          break\n",
    "\n",
    "\n",
    "      shot_detected=shot_raw[int(timee*44100)]\n",
    "      if shot_detected and not prev_frame_shot:\n",
    "          first_frame_of_shot=True\n",
    "      else:\n",
    "          first_frame_of_shot=False\n",
    "      prev_frame_shot=shot_detected\n",
    "      output = np.zeros_like(frame)\n",
    "      image_np = np.array(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "      gaze,gaze_bbox=get_gaze(image_np)\n",
    "\n",
    "      detections=get_detections(image_np,detect_fn)\n",
    "\n",
    "      detections=deduplicate(detections,MIN_CONF_THRESH)\n",
    "\n",
    "      if(beam==False):\n",
    "        avatar_is_blue=get_avatar_is_blue(image_np,detections,avatar_is_blue_model)\n",
    "\n",
    "      avatar,avatar_bbox, arrow, arrow_bbox, sphere,sphere_bbox = get_object_and_bbox(detections)\n",
    "      arrow_is_left,arrow_is_white=arrow_is_left_white(image_np,detections,left_model,red_model)\n",
    "\n",
    "      gaze_at_arrow=get_gaze_at_arrow(gaze, gaze_bbox,arrow,arrow_bbox)\n",
    "\n",
    "      #3 times the length of bounding boxes in gaze_at_avatar\n",
    "      if gaze_bbox!=None and avatar_bbox!=None:\n",
    "        ymin, xmin, ymax, xmax=gaze_bbox\n",
    "        ymid=(ymax+ymin)/2\n",
    "        three_ymax=min(ymid+(ymax-ymid)*3,1080)\n",
    "        three_ymin=max(ymid-(ymax-ymid)*3,0)\n",
    "        xmid=(xmax+xmin)/2\n",
    "        three_xmax=min(xmid+(xmax-xmid)*3,1920)\n",
    "        three_xmin=max(xmid-(xmax-xmid)*3,0)\n",
    "        three_gaze_bbox=(three_ymin, three_xmin, three_ymax, three_xmax)\n",
    "\n",
    "        ymin, xmin, ymax, xmax=avatar_bbox\n",
    "        ymid=(ymax+ymin)/2\n",
    "        three_ymax=min(ymid+(ymax-ymid)*3,1080)\n",
    "        three_ymin=max(ymid-(ymax-ymid)*3,0)\n",
    "        xmid=(xmax+xmin)/2\n",
    "        three_xmax=min(xmid+(xmax-xmid)*3,1920)\n",
    "        three_xmin=max(xmid-(xmax-xmid)*3,0)\n",
    "        three_avatar_bbox=(three_ymin, three_xmin, three_ymax, three_xmax)\n",
    "      else:\n",
    "        three_gaze_bbox=None\n",
    "        three_avatar_bbox=None\n",
    "\n",
    "      gaze_at_avatar=get_gaze_at_avatar(gaze, three_gaze_bbox,avatar,three_avatar_bbox)\n",
    "      sphere_at_avatar=get_sphere_at_avatar(sphere, sphere_bbox,avatar,avatar_bbox)\n",
    "\n",
    "      if draw==True:\n",
    "        image_np_with_detections = image_np.copy()\n",
    "        viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "              image_np_with_detections,\n",
    "              detections['detection_boxes'],\n",
    "              detections['detection_classes'],\n",
    "              detections['detection_scores'],\n",
    "              category_index,\n",
    "              use_normalized_coordinates=True,\n",
    "              min_score_thresh=MIN_CONF_THRESH,\n",
    "              agnostic_mode=False)\n",
    "        image_np_with_detections=impose_gaze_sqaure(image_np_with_detections,gaze,gaze_bbox)\n",
    "        image_np_with_detections=impose_inference_text(image_np_with_detections,gaze_at_arrow,gaze_at_avatar,sphere_at_avatar)\n",
    "        image_np_with_detections=impose_frame_count(image_np_with_detections,frame_count)\n",
    "        if arrow==True:\n",
    "          image_np_with_detections=impose_left_text(image_np_with_detections,arrow_is_left)\n",
    "          image_np_with_detections=impose_red_text(image_np_with_detections,not arrow_is_white)\n",
    "        if shot_detected==True:\n",
    "          image_np_with_detections=impose_shot_detected_text(image_np_with_detections,shot_detected)\n",
    "        if beam==False and avatar==True:\n",
    "          image_np_with_detections=impose_avatar_text(image_np_with_detections,avatar_is_blue)\n",
    "        out.write(cv2.cvtColor(image_np_with_detections,cv2.COLOR_RGB2BGR))\n",
    "\n",
    "\n",
    "\n",
    "      avatar_ymin,avatar_xmin,avatar_ymax,avatar_xmax,arrow_ymin,arrow_xmin,arrow_ymax,arrow_xmax,sphere_ymin,sphere_xmin,sphere_ymax,sphere_xmax,avatar_ymid,gaze_ymin,gaze_xmin,gaze_ymax,gaze_xmax=[None for i in range(17)]\n",
    "      if avatar_bbox!=None:\n",
    "        avatar_ymin,avatar_xmin,avatar_ymax,avatar_xmax=avatar_bbox\n",
    "        avatar_ymid=round((avatar_ymin+avatar_ymax)/2)\n",
    "      if arrow_bbox!=None:\n",
    "        arrow_ymin,arrow_xmin,arrow_ymax,arrow_xmax=arrow_bbox\n",
    "      if sphere_bbox!=None:\n",
    "        sphere_ymin,sphere_xmin,sphere_ymax,sphere_xmax=sphere_bbox\n",
    "      if gaze_bbox!=None:\n",
    "        gaze_ymin,gaze_xmin,gaze_ymax,gaze_xmax=gaze_bbox\n",
    "      if first_frame_of_shot==True and sphere==False:\n",
    "        sphere_is_estimated=True\n",
    "      else:\n",
    "        sphere_is_estimated=False\n",
    "\n",
    "      if avatar==True and arrow==True:\n",
    "        avatar_LR=-1 if (avatar_xmin+avatar_xmax)/2<(arrow_xmin+arrow_xmax)/2 else 1\n",
    "\n",
    "      if avatar==False:\n",
    "        avatar_is_blue=None\n",
    "      if arrow==False:\n",
    "        arrow_is_left=None\n",
    "        arrow_is_white=None\n",
    "\n",
    "      row_data = [timee, frame_count,trial_count,trial_start_time,saccade_rt,manual_rt,arrow_is_left,arrow_is_white,avatar_direction,avatar_color,\n",
    "                  avatar_is_blue,arrow, arrow_count,arrow_is_5_to_8_frames_before_avatar,\n",
    "                  avatar,avatar_count,avatar_is_5_to_8_frames_after_arrow,gaze_at_arrow,first_frame_of_gaze_at_avatar,gaze_at_avatar,\n",
    "                  first_frame_of_shot,sphere_at_avatar,arrow_remains_longtime,avatar_remains_longtime,\n",
    "                  arrow_bbox,arrow_ymin,arrow_xmin,arrow_ymax,arrow_xmax,\n",
    "                  avatar_bbox, avatar_ymin,avatar_xmin,avatar_ymax,avatar_xmax,avatar_ymid,avatar_LR,\n",
    "                  sphere, sphere_is_estimated, sphere_bbox,sphere_ymin,sphere_xmin,sphere_ymax,sphere_xmax,\n",
    "                  gaze,gaze_bbox,gaze_ymin,gaze_xmin,gaze_ymax,gaze_xmax,\n",
    "                  shot_detected]\n",
    "      data.append(row_data)\n",
    "      frame_count+=1\n",
    "  cap.release()\n",
    "\n",
    "  columns = ['timee', 'frame_count', 'trial_count', 'trial_start_time', 'saccade_rt', 'manual_rt', 'arrow_is_left', 'arrow_is_white','avatar_direction','avatar_color',\n",
    "                 'avatar_is_blue', 'arrow', 'arrow_count', 'arrow_is_5_to_8_frames_before_avatar',\n",
    "                 'avatar', 'avatar_count', 'avatar_is_5_to_8_frames_after_arrow', 'gaze_at_arrow', 'first_frame_of_gaze_at_avatar', 'gaze_at_avatar',\n",
    "                 'first_frame_of_shot', 'sphere_at_avatar', 'arrow_remains_longtime', 'avatar_remains_longtime',\n",
    "                'arrow_bbox', 'arrow_ymin', 'arrow_xmin', 'arrow_ymax', 'arrow_xmax',\n",
    "                 'avatar_bbox', 'avatar_ymin', 'avatar_xmin', 'avatar_ymax', 'avatar_xmax', 'avatar_ymid','avatar_LR',\n",
    "                 'sphere', 'sphere_is_estimated', 'sphere_bbox', 'sphere_ymin', 'sphere_xmin', 'sphere_ymax', 'sphere_xmax',\n",
    "                 'gaze', 'gaze_bbox', 'gaze_ymin', 'gaze_xmin', 'gaze_ymax', 'gaze_xmax',\n",
    "                 'shot_detected']\n",
    "\n",
    "  df = pd.DataFrame(data, columns=columns)\n",
    "  df.to_csv(CSV_PATH, index=False)\n",
    "  post_processing_csv(CSV_PATH)\n",
    "\n",
    "  if draw:\n",
    "    out.release()\n",
    "    #add_audio_to_video(VIDEO_PATH, OUTPUT_PATH, OUTPUT_PATH.split('.')[0]+'with_sound.'+OUTPUT_PATH.split('.')[1])\n",
    "\n",
    "  print('Done! Took {} seconds'.format(time.time()-start_time))\n",
    "  print(str(frame_count)+' frame processed; '+OUTPUT_PATH+' generated')\n",
    "  print(CSV_PATH+' generated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://urldefense.com/v3/__https://localhost:8080/__;!!Mih3wA!Eje2quypq1bAeOMOG3OnSP2svxHfzube5cergsflZZBbbXXWH87Q4OGbjy9vgwGZGQCT2s2pIsZdY1g6zw$ "
    },
    "id": "1d94YeqYXAZu",
    "outputId": "bbe19797-ec73-4cbe-ad91-fe57ca8d491e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "videos/V008_0Back.mp4 predictions/videos/V008_0Back.avi predictions/csvs/V008_0Back.csv True False\n",
      "Video resolution: 1920x1080\n",
      "Video fps: 25\n",
      "Total number of frames: 13620\n",
      "processing now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/var/folders/g1/x4mb78rn3k33l5nmxr2wf3t80000gn/T/ipykernel_13123/3819990451.py:21: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  process(video_list[i],output_list[i],csv_list[i],True,'BEAM' in video_list[i])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-08 17:25:22.129749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-08 17:25:46.168298: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-08 17:25:46.270386: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-09-08 17:25:48.111793: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n",
      "11000\n",
      "11200\n",
      "11400\n",
      "11600\n",
      "11800\n",
      "12000\n",
      "12200\n",
      "12400\n",
      "12600\n",
      "12800\n",
      "13000\n",
      "13200\n",
      "13400\n",
      "13600\n",
      "Done! Took 4103.441537857056 seconds\n",
      "13620 frame processed; predictions/videos/V008_0Back.avi generated\n",
      "predictions/csvs/V008_0Back.csv generated\n",
      "0 is done!\n",
      "videos/V008_BEAM.mp4 predictions/videos/V008_BEAM.avi predictions/csvs/V008_BEAM.csv True True\n",
      "Video resolution: 1920x1080\n",
      "Video fps: 25\n",
      "Total number of frames: 20048\n",
      "processing now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/var/folders/g1/x4mb78rn3k33l5nmxr2wf3t80000gn/T/ipykernel_13123/3819990451.py:21: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  process(video_list[i],output_list[i],csv_list[i],True,'BEAM' in video_list[i])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n",
      "11000\n",
      "11200\n",
      "11400\n",
      "11600\n",
      "11800\n",
      "12000\n",
      "12200\n",
      "12400\n",
      "12600\n",
      "12800\n",
      "13000\n",
      "13200\n",
      "13400\n",
      "13600\n",
      "13800\n",
      "14000\n",
      "14200\n",
      "14400\n",
      "14600\n",
      "14800\n",
      "15000\n",
      "15200\n",
      "15400\n",
      "15600\n",
      "15800\n",
      "16000\n",
      "16200\n",
      "16400\n",
      "16600\n",
      "16800\n",
      "17000\n",
      "17200\n",
      "17400\n",
      "17600\n",
      "17800\n",
      "18000\n",
      "18200\n",
      "18400\n",
      "18600\n",
      "18800\n",
      "19000\n",
      "19200\n",
      "19400\n",
      "19600\n",
      "19800\n",
      "20000\n",
      "Done! Took 5877.531508922577 seconds\n",
      "20048 frame processed; predictions/videos/V008_BEAM part2.avi generated\n",
      "predictions/csvs/V008_BEAM.csv generated\n",
      "1 is done!\n",
      "videos/P051_V059_BEAM.mp4 predictions/videos/P051_V059_BEAM.avi predictions/csvs/P051_V059_BEAM.csv True True\n",
      "Video resolution: 1920x1080\n",
      "Video fps: 25\n",
      "Total number of frames: 20641\n",
      "processing now\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/var/folders/g1/x4mb78rn3k33l5nmxr2wf3t80000gn/T/ipykernel_13123/3819990451.py:21: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  process(video_list[i],output_list[i],csv_list[i],True,'BEAM' in video_list[i])\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n",
      "11000\n",
      "11200\n",
      "11400\n",
      "11600\n",
      "11800\n",
      "12000\n",
      "12200\n",
      "12400\n",
      "12600\n",
      "12800\n",
      "13000\n",
      "13200\n",
      "13400\n",
      "13600\n",
      "13800\n",
      "14000\n",
      "14200\n",
      "14400\n",
      "14600\n",
      "14800\n",
      "15000\n",
      "15200\n",
      "15400\n",
      "15600\n",
      "15800\n",
      "16000\n",
      "16200\n",
      "16400\n",
      "16600\n",
      "16800\n",
      "17000\n",
      "17200\n",
      "17400\n",
      "17600\n",
      "17800\n",
      "18000\n",
      "18200\n",
      "18400\n",
      "18600\n",
      "18800\n",
      "19000\n",
      "19200\n",
      "19400\n",
      "19600\n",
      "19800\n",
      "20000\n",
      "20200\n",
      "20400\n",
      "20600\n",
      "Done! Took 5441.037034988403 seconds\n",
      "20641 frame processed; predictions/videos/P051_V059_BEAM part2.avi generated\n",
      "predictions/csvs/P051_V059_BEAM.csv generated\n",
      "2 is done!\n"
     ]
    }
   ],
   "source": [
    "#VPATH = path with videos to be processed\n",
    "VPATH = 'videos/'\n",
    "#output path for csv files'\n",
    "CSVPATH = 'predictions/csvs/'\n",
    "OUTPUTPATH='/Users/fusionmac/Documents/TBICoE/FusionVR/content/predictions/videos/'\n",
    "video_list=[]\n",
    "output_list=[]\n",
    "csv_list=[]\n",
    "tmp_list=['V059','V008']\n",
    "for path in os.listdir(VPATH):\n",
    "  for i in tmp_list:\n",
    "    if i in path:\n",
    "      video_list.append(VPATH + path)\n",
    "      output_list.append((OUTPUTPATH+path).split('.')[0]+'.avi')\n",
    "      csv_list.append(CSVPATH+path.split('.')[0]+'.csv')\n",
    "      break\n",
    "\n",
    "i=0\n",
    "while i<len(video_list):\n",
    "  print(video_list[i],output_list[i],csv_list[i],True,'BEAM' in video_list[i])\n",
    "  process(video_list[i],output_list[i],csv_list[i],True,'BEAM' in video_list[i])\n",
    "  print(str(i)+\" is done!\")\n",
    "  i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
